import os
import re

from tts_audiobook_tool.ansi import Ansi
from tts_audiobook_tool.app_types import Hint

package_dir = os.path.dirname(os.path.abspath(__file__))

APP_NAME = "tts-audiobook-tool"

APP_USER_SUBDIR = "tts_audiobook_tool"
APP_TEMP_SUBDIR = "tts_audiobook_tool"
ASSETS_DIR_NAME = "assets"

PROJECT_SOUND_SEGMENTS_SUBDIR = "segments"
PROJECT_CONCAT_SUBDIR = "combined"
PROJECT_JSON_FILE_NAME = "project.json"
PROJECT_TEXT_SEGMENTS_FILE_NAME = "text_segments.json"
PROJECT_TEXT_RAW_FILE_NAME = "text_raw.txt"
PROJECT_CONCAT_TEMP_TEXT_FILE_NAME = "ffmpeg_temp.txt"
PROJECT_DEFAULT_LANGUAGE = "en"
PREFS_FILE_NAME = "tts-audiobook-tool-prefs.json"

FFMPEG_COMMAND = "ffmpeg"

STT_TEMP_TRANSCRIBED_WORDS = "temp_words.pkl"
VALIDATION_UNSUPPORTED_LANGUAGES = ["zh", "ja", "ko"]

# App uses a single sample rate for any sound transformations up until outputting final audio
# This is useful because a single project can use different models which may have different native
# output sample rates.
APP_SAMPLE_RATE = 44100

# Samplerate required for whisper audio input
WHISPER_SAMPLERATE = 16000

DEFAULT_MAX_WORDS_PER_SEGMENT = 40
MIN_MAX_WORDS_PER_SEGMENT = 20
MAX_MAX_WORDS_PER_SEGMENT = 80

CTRANSLATE_REQUIRED_CUDNN_VERSION = 90100

OUTE_DEFAULT_VOICE_JSON_FILE_NAME = "en-female-1-neutral.json"
OUTE_DEFAULT_VOICE_JSON_FILE_PATH = os.path.join(package_dir, ASSETS_DIR_NAME, OUTE_DEFAULT_VOICE_JSON_FILE_NAME)

# App's typical ffmpeg options wrt console output, etc
FFMPEG_TYPICAL_OPTIONS = [
    "-y",  # Overwrite output file if it exists
    "-hide_banner", "-loglevel", "warning",
    "-stats"
]

FFMPEG_ARGUMENTS_OUTPUT_FLAC = [
    "-c:a", "flac",
    "-sample_fmt",  "s16",
    "-frame_size", "4096",
    "-compression_level", "6"
]
FFMPEG_ARGUMENTS_OUTPUT_AAC = [
    "-c:a", "aac",
    "-b:a", f"96k",
    "-movflags", "+faststart", # moves metadata to the front, for streaming, which we want
    '-vn',                    # No video (important when input is mp3 for some reason)
    # Do not use "-sample_fmt s16" here
]

APP_META_FLAC_FIELD = "TTS_AUDIOBOOK_TOOL"
APP_META_MP4_MEAN = "tts-audiobook-tool"
APP_META_MP4_TAG = "audiobook-data"

AAC_SUFFIXES = [".m4a", ".m4b", ".mp4"]

COL_ACCENT = Ansi.hex("ffaa44")
COL_ERROR = Ansi.hex("ff0000")
COL_DIM = Ansi.hex("666666")
COL_INPUT = Ansi.hex("aaaaaa")
COL_OK = Ansi.hex("00ff00")
COL_DEFAULT = Ansi.RESET

PLAYER_URL = "https://zeropointnine.github.io/tts-audiobook-tool/browser_player/"

SECTION_SOUND_EFFECT_PATH = os.path.join(package_dir, ASSETS_DIR_NAME, "page-turn-a.wav")

FILE_REQUESTOR_SOUND_TYPES = [('Sound files', '*.wav *.flac *.mp3,*.aac,*.m4a,*.ogg'), ('All files', '*.*')]

# App uses this format for file names of audio fragments.
# Example file name: "[00001] [0123456789ABCDEF] [my_voice] [any_other_bracketed_tags] Hello_world.flac"
# Capturing group 1 is segment index - digits enclosed in brackets (eg, "00001")
# Capturing group 2 is hex hash - 16 hex characters enclosed brackets (eg, "0123456789ABCDEF")
# Capturing group 3 is voice label - alphanumeric chars (and underscores) enclosed in brackets
# Rest of string can be anything
pattern = r"\[(\d+)\] \[([0-9A-Fa-f]{16})\] \[(\w+)\] .*"
AUDIO_SEGMENT_FILE_NAME_PATTERN = re.compile(pattern)

# Regex for "[h...]", where "h" is 16 hex characters.
# Captures the hex string (w/o the brackets)
# Eg, "[0123456789ABCDEF]"
# App uses this format for including 64-bit hash values in filenames.
pattern = r'\[([0-9a-fA-F]{16})\]'
HASH_PATTERN = re.compile(pattern)

# ---

HINT_LONG_PATHS = Hint(
    "long_paths",
    "It appears your system does not support long file paths",
    "App relies on pretty long filenames, so be sure to use\nshort directory paths when creating new projects"
)

HINT_OUTE_CONFIG = Hint(
    "oute_config",
    "This appears to be your first time running the application using the Oute TTS model",
    "As a reminder, you'll want to review and adjust the settings\nin the file \"config_oute.py\" for optimal performance."
)

HINT_INDEXTTS2 = Hint(
    "indextts2",
    "This appears to be your first time running the application using the IndexTTS2 model",
"""Consider disabling transcription validation for this model,
as IndexTTS2 is accurate enough to make this extra step unnecessary.
(Options > Whisper transcription model > Disabled)"""
)

HINT_TKINTER = Hint(
    "tkinter",
    "tkinter not installed",
    "Please install \"tkinter\" if you want OS file requestor functionality (It is not required, though)."
)

HINT_PROJECT_SUBDIRS = Hint(
    "project_subdirs",
    "Within your newly created project directory...",
f"""The {COL_ACCENT}segments{COL_DEFAULT} subdirectory contains the individual audio segments generated by the TTS model.
The {COL_ACCENT}combined{COL_DEFAULT} subdirectory contains the final, concatenated audio file/s ready for playing."""
)

HINT_LINE_BREAKS = Hint(
    "line_breaks",
    "Note:",
    "Line breaks are treated as paragraph delimiters.\nIf your source text uses manual line breaks for word wrapping\n(eg, Project Gutenberg), you will want to reformat it first."
)

HINT_REGEN = Hint(
    "regenerate",
    "About...",
"""The validation algorithm is tuned to be on the conservative side,
which means lines tagged as having potential errors usually *do* have errors
(so long as the text itself is not too unconventional), but it will also 
miss errors as well.

Some lines tagged with errors may not be easily correctable,
even after multiple attempts."""
)

HINT_REAL_TIME = Hint(
    "real_time",
    "About",
f"""This uses the same quality-control steps as the normal "Generate" workflow,
aside from loudness normalization.

To achieve uninterrupted playback, your system must be able to
do the audio inference faster-than-realtime.

Note that lines get validated and potentially re-generated only when there is
enough buffered audio to allow for uninterrupted playback (60 seconds)."""
)

HINT_MULTIPLE_MP3S = Hint(
    "multiple_mp3s",
    "Multiple MP3 files?",
    "If you want to combine multiple MP3 files in a directory,\nthis can be done from the Tools/Options menu"
)

HINT_OUTE_LOUD_NORM = Hint(
    "oute_loud_norm",
    "Tip",
    "Oute generations can have considerable variance in loudness.\nConsider using \"stronger.\""
)

HINT_FISH_FIRST = Hint(
    "fish_first",
    "Please note...",
"""On the very first inference, the Fish model may go through a compilation step
which may take 1-2 minutes without any feedback shown."""
)

HINT_NO_VOICE = Hint(
    "gen_no_voice",
    "No voice clone defined",
    "The TTS model will generate random-sounding voices because no voice sample has been set."
)

HINT_TEST_REAL_TIME = Hint(
    "test_real_time",
    "Tip",
"""After setting voice clone or changing other model properties,
consider using \"Menu > Generate audio in realtime\" to quickly test audio
generation quality before committing to generating audiobook.
"""
)

HINT_TRANSCRIPTION = Hint(
    "transcription",
    "Note",
"""The Whisper transcription model to check the generated audio for errors.
Because it is used concurrently with the text-to-speech model,
it adds 2-3 GB to VRAM memory requirements."""
)

HINT_SPEED_UP = Hint(
    "speed_up",
    "Note",
"""Use this feature to create a sped-up (or slowed-down) copy of a voice clone sample.
This can be useful for modulating the speed of narration of the generated audio."""
)

HINT_INDEX_SAMPLE_LEN = Hint(
    "index_sample_len",
    "Note",
    """IndexTTS2 ignores voice sample audio data past the 15 second mark"""
)

HINT_STT_ENHANCE = Hint(
    "stt_enhance",
    "Text preparation...",
"""It's recommended to first remove any large chunks
from the source text that do not occur in the audio narration.
Common examples are: publisher information, table of contents, etc"""
)

HINT_STT_ENHANCE_CACHED = Hint(
    "stt_enhance_cached",
    "Transcription data is cached",
"""If you feel the need to modify the source text to minimize \"discontinuities\",
you can re-run the \"Enhance existing audiobook\" process, and it will run faster
the second time through, as the audio transcription data has been cached."""
)


HINT_LINUX_CUDNN_VERSION = Hint(
    "stt_linux_cudnn_version",
    f"{COL_ERROR}cuDNN version mismatch!",
f"""The installed version of torch is incompatible with faster-whisper CUDA acceleration.
Either downgrade your version of torch (see README file), or change the Whisper 
device to CPU ({COL_ACCENT}Options > Whisper config > CPU{COL_DEFAULT}).""")

HINT_SEG_STRATEGY = Hint("seg", "",
"""When text is imported to the project, this dictates how
it is segmented for text-to-speech inference.""")

HINT_SEG_MAX_SIZE = Hint("seg", "",
f"""When text is imported to the project, this dictates the maximum number of
words for each text segment.

Increasing this value beyond the default of {DEFAULT_MAX_WORDS_PER_SEGMENT} should be done
with some care and extra testing (Some models may emit more errors or fail).
The value is saved on a per-model basis.""")

HINT_MAX_WORDS_OVER_DEFAULT_MESSAGE = """The project's source text word count per segment (%1)
exceeds the application's default ("safe") value (%2).
Make sure this is what you want before generating audio."""

HINT_CHATTERBOX_PYTHON_DOWNGRADE = Hint(
    "chatterbox_python_downgrade",
    "The app's requirements for Chatterbox have changed",
"""To run the Chatterbox model, the app now requires a virtual environment running Python 3.11 (which is a downgrade). 
Please re-install your Chatterbox-specific virtual environment using Python v3.11 by following the procedure described in the README.
You could also choose to roll back to a previous commit if you do not care about the most recent updates..."""
)

HINT_VALIDATION_UNSUPPORTED_LANGUAGE = Hint(
    "validation_unsupported_language",
    "Transcription validation will be disabled",
    "Transcription-based validation is unsupported for %1 "
"and will be automatically disabled."
)